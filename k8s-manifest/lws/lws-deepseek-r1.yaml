apiVersion: leaderworkerset.x-k8s.io/v1
kind: LeaderWorkerSet
metadata:
  name: lws-deepseek-r1-sglang
spec:
  replicas: 1
  leaderWorkerTemplate:
    size: 2
    restartPolicy: None
    leaderTemplate:
      metadata:
        labels:
          role: leader
      spec:
        priorityClassName: high-priority-100
        nodeSelector:
          node.kubernetes.io/instance-type: p5en.48xlarge
        tolerations:
        - key: "nvidia.com/gpu"
          operator: "Exists"
          effect: "NoSchedule"
        containers:
        - name: sglang-leader
          image: docker.io/lmsysorg/sglang:latest
          imagePullPolicy: Always
          command: [ "python3", "-m", "sglang.launch_server" ]
          args: [ 
            "--model-path", "deepseek-ai/DeepSeek-R1", 
            "--host", "0.0.0.0", 
            "--port", "8000", 
            "--tensor-parallel-size", "16",
            "--quantization", "fp8",
            "--mem-fraction-static", "0.85", 
            "--disable-custom-all-reduce", 
            "--attention-backend", "flashinfer",
            "--trust-remote-code", 
            "--enable-p2p-check", 
            "--enable-ep-moe",
            "--dist-init-addr", "$(LWS_LEADER_ADDRESS):20000",
            "--nnodes", "$(LWS_GROUP_SIZE)",
            "--node-rank", "$(LWS_WORKER_INDEX)",
          ]
          env:
          - name: LWS_WORKER_INDEX
            valueFrom:
              fieldRef:
                fieldPath: metadata.labels['leaderworkerset.sigs.k8s.io/worker-index']
          # NCCL Configuration with proper EFA support
          - name: NCCL_DEBUG
            value: "INFO"
          # Fixed NCCL_SOCKET_IFNAME to use EFA interface properly
          - name: NCCL_SOCKET_IFNAME
            value: "eth0"  # Use primary network interface instead of excluding interfaces
          - name: NCCL_P2P_DISABLE
            value: "0"
          - name: NCCL_P2P_LEVEL
            value: "NVL"
          - name: NCCL_NVLS_ENABLE
            value: "0"  # Disable NVLS for EFA compatibility
          # EFA Configuration - properly configured
          - name: FI_PROVIDER
            value: "efa"
          - name: FI_EFA_USE_DEVICE_RDMA
            value: "1"
          - name: FI_EFA_FORK_SAFE
            value: "1"
          - name: RDMAV_FORK_SAFE
            value: "1"
          # Additional EFA settings for better performance
          - name: FI_EFA_ENABLE_SHM_TRANSFER
            value: "1"
          # PyTorch Configuration
          - name: TORCH_USE_CUDA_DSA
            value: "1"
          # ADD THESE FOR EFA:
          - name: NCCL_NET_PLUGIN
            value: "/opt/amazon/aws-ofi-nccl/lib/libnccl-net-aws-ofi.so"
          - name: LD_LIBRARY_PATH
            value: "/opt/amazon/aws-ofi-nccl/lib:/opt/amazon/efa/lib:/usr/local/cuda/lib64:/usr/local/lib"
          - name: SGL_ENABLE_JIT_DEEPGEMM
            value: "0"
          ports:
          - name: http
            containerPort: 8000
          - name: nccl
            containerPort: 20000
          resources:
            limits:
              vpc.amazonaws.com/efa: "16"
              nvidia.com/gpu: "8"
          startupProbe:
            tcpSocket:
              port: 8000
            initialDelaySeconds: 180
            periodSeconds: 30
            timeoutSeconds: 10
            failureThreshold: 60  # Allow up to 30 minutes for startup (60 * 30s = 1800s)
          readinessProbe:
            tcpSocket:
              port: 8000
            initialDelaySeconds: 30  # Wait 30 seconds before first readiness check
            periodSeconds: 30
            timeoutSeconds: 10
            failureThreshold: 10
          volumeMounts:
          - mountPath: /root/.cache/huggingface
            name: cache-volume
          - name: shm
            mountPath: /dev/shm
          # Mount EFA devices
          - name: efa-devices
            mountPath: /dev/infiniband
          securityContext:
            capabilities:
              add:
                - IPC_LOCK
                - SYS_RESOURCE
        volumes:
        - name: cache-volume
          hostPath:
            path: /mnt/k8s-disks/0/models/deepseek
            type: DirectoryOrCreate
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: "500Gi"
        - name: efa-devices
          hostPath:
            path: /dev/infiniband
            type: Directory
    workerTemplate:
      spec:
        priorityClassName: high-priority-100
        nodeSelector:
          node.kubernetes.io/instance-type: p5en.48xlarge
        tolerations:
        - key: "nvidia.com/gpu"
          operator: "Exists"
          effect: "NoSchedule"
        containers:
        - name: sglang-worker
          image: docker.io/lmsysorg/sglang:latest
          imagePullPolicy: Always
          command: [ "python3", "-m", "sglang.launch_server" ]
          args: [ 
                "--model-path", "deepseek-ai/DeepSeek-R1", 
                "--host", "0.0.0.0", 
                "--port", "8000", 
                "--tensor-parallel-size", "16",
                "--quantization", "fp8",
                "--mem-fraction-static", "0.85", 
                "--disable-custom-all-reduce", 
                "--attention-backend", "flashinfer",
                "--trust-remote-code", 
                "--enable-p2p-check", 
                "--enable-ep-moe",
                "--dist-init-addr", "$(LWS_LEADER_ADDRESS):20000",
                "--nnodes", "$(LWS_GROUP_SIZE)",
                "--node-rank", "$(LWS_WORKER_INDEX)",
              ]
          env:
          - name: LWS_WORKER_INDEX
            valueFrom:
              fieldRef:
                fieldPath: metadata.labels['leaderworkerset.sigs.k8s.io/worker-index']
          # NCCL Configuration with proper EFA support
          - name: NCCL_DEBUG
            value: "INFO"
          # Fixed NCCL_SOCKET_IFNAME to use EFA interface properly
          - name: NCCL_SOCKET_IFNAME
            value: "eth0"  # Use primary network interface instead of excluding interfaces
          - name: NCCL_P2P_DISABLE
            value: "0"
          - name: NCCL_P2P_LEVEL
            value: "NVL"
          - name: NCCL_NVLS_ENABLE
            value: "0"  # Disable NVLS for EFA compatibility
          # EFA Configuration - properly configured
          - name: FI_PROVIDER
            value: "efa"
          - name: FI_EFA_USE_DEVICE_RDMA
            value: "1"
          - name: FI_EFA_FORK_SAFE
            value: "1"
          - name: RDMAV_FORK_SAFE
            value: "1"
          # Additional EFA settings for better performance
          - name: FI_EFA_ENABLE_SHM_TRANSFER
            value: "1"
          # PyTorch Configuration
          - name: TORCH_USE_CUDA_DSA
            value: "1"
          # ADD THESE FOR EFA:
          - name: NCCL_NET_PLUGIN
            value: "/opt/amazon/aws-ofi-nccl/lib/libnccl-net-aws-ofi.so"
          - name: LD_LIBRARY_PATH
            value: "/opt/amazon/aws-ofi-nccl/lib:/opt/amazon/efa/lib:/usr/local/cuda/lib64:/usr/local/lib"
          - name: SGL_ENABLE_JIT_DEEPGEMM
            value: "0"
          ports:
          - name: http
            containerPort: 8000
          - name: nccl
            containerPort: 20000
          resources:
            limits:
              vpc.amazonaws.com/efa: "16"
              nvidia.com/gpu: "8"
            requests:
              vpc.amazonaws.com/efa: "16"
              nvidia.com/gpu: "8"
          startupProbe:
            tcpSocket:
              port: 8000
            initialDelaySeconds: 180
            periodSeconds: 30
            timeoutSeconds: 10
            failureThreshold: 60  # Allow up to 30 minutes for startup (60 * 30s = 1800s)
          readinessProbe:
            tcpSocket:
              port: 8000
            initialDelaySeconds: 30  # Wait 30 seconds before first readiness check
            periodSeconds: 30
            timeoutSeconds: 10
            failureThreshold: 10
          livenessProbe:
            tcpSocket:
              port: 8000
            initialDelaySeconds: 600  # Wait 10 minutes before first liveness check
            periodSeconds: 60
            timeoutSeconds: 30
            failureThreshold: 5
          volumeMounts:
          - mountPath: /root/.cache/huggingface
            name: cache-volume
          - name: shm
            mountPath: /dev/shm
          # Mount EFA devices
          - name: efa-devices
            mountPath: /dev/infiniband
          securityContext:
            capabilities:
              add:
                - IPC_LOCK
                - SYS_RESOURCE
        volumes:
        - name: cache-volume
          hostPath:
            path: /mnt/k8s-disks/0/models/deepseek
            type: DirectoryOrCreate
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: "500Gi"
        - name: efa-devices
          hostPath:
            path: /dev/infiniband
            type: Directory
---
apiVersion: v1
kind: Service
metadata:
  name: deepseek-r1-leader
spec:
  selector:
    leaderworkerset.sigs.k8s.io/name: lws-deepseek-r1-sglang
    role: leader
  ports:
  - name: http
    protocol: TCP
    port: 80
    targetPort: http
  - name: nccl
    protocol: TCP
    port: 20000
    targetPort: nccl
  type: ClusterIP
